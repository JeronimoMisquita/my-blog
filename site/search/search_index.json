{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"System Design - By Jeronimo","text":""},{"location":"Distributed%20Systems/Replication/","title":"Replication","text":"<p>Replication means keeping identical copies of data across multiple nodes (machines) connected via a network.</p> <p>Benefits of Replication:</p> <ol> <li>Provides data locality by keeping data geographically close to users. I.e improves latency from client perspective</li> <li>Enables scaling of read operations. i.e Scalability</li> <li>Supports disaster recovery and high availability.</li> </ol> <p>Assumption: For simplicity, assume the dataset is small enough to fit on a single node.</p>"},{"location":"Distributed%20Systems/Replication/#algorithms-for-replicating-changes","title":"Algorithms for Replicating Changes","text":"<ol> <li>Single Leader Replication</li> <li>Multi-Leader Replication</li> <li>Leaderless Replication</li> </ol>"},{"location":"Distributed%20Systems/Replication/#1-leader-based-replication","title":"1. Leader-Based Replication","text":"<ul> <li>One node is designated as the leader.</li> <li>The leader receives all write requests from clients and persists them to its local storage.</li> <li>After persisting the data, the leader propagates changes to follower nodes via a replication log or change stream.</li> <li>Followers apply writes from the leader to their local storage in the same order as processed on the leader.</li> </ul> <p>Note: Clients can only write to the leader, but may read from either the leader or any follower.</p> <p>Common Use Cases: - Relational databases (e.g., PostgreSQL, MySQL) - Non-relational databases (e.g., MongoDB, RethinkDB) - Distributed message brokers (e.g., Kafka, RabbitMQ) - Some distributed filesystems</p>"},{"location":"Distributed%20Systems/Replication/#synchronous-vs-asynchronous-replication","title":"Synchronous vs. Asynchronous Replication","text":"<ul> <li>After the leader applies a write, it will wait for synchronous replicas to confirm the change before acknowledging the client.</li> <li>Advantage: If the leader fails, a synchronous follower is guaranteed to have the latest committed data and can be promoted to leader.</li> <li> <p>Disadvantage: If any required synchronous replica is unavailable, the system cannot accept new writes.</p> </li> <li> <p>It is impractical for all nodes to be synchronous, as this increases write latency and reduces availability (even if one replica is down the system cant accept writes at all).</p> </li> <li> <p>The system may also operate with all nodes in asyc mode</p> </li> <li>Advantage: Faster write acknowledgments; the system can accept writes even if all followers are offline.</li> <li>Disadvantage: If the leader fails, writes not yet replicated to followers may be lost, meaning durability is not guaranteed even if the client received an acknowledgment.</li> </ul>"},{"location":"Distributed%20Systems/Replication/#setting-up-new-followers","title":"Setting up new followers","text":"<p>New followers can be added to increase the number of read replicas or to replace failed ones. The process can usually be done without any downtime. </p> <p>Steps: 1. Take a snapshot of the leader DB. This can usually be done without downtime (It's a common task while taking a DB backup). The snapshot also exactly correlates to one point in the leader's replication log. In PostgreSQL, this exact position is called the log sequence number, and in MySQL, it is called binlog coordinates. 2. The snapshot is copied to the new follower node. 3. The follower connects to the leader and requests all the changes since the snapshot was taken (delta). 4. Once the follower has processed the backlog of data changes, it has caught up and begins processing data changes from the leader as they happen.</p>"},{"location":"Distributed%20Systems/Replication/#handling-node-outages","title":"Handling node outages","text":"<ol> <li>Follower Failure</li> </ol> <p>The follower disconnect temporarily from leader. Either due to reboot (e.g during OS upgrade) or network disruption. The follower usually maintains a log of data changes it processed from the leader. When the follower comes back, it simply looks up the last transaction that it processed and can request subsequent changes from the leader. Once the backlog is processed, the follower has caught up and starts processing updates from the leader as they happen.</p> <ol> <li>Leader Failure</li> </ol> <p>Quite tricky. In process called Failover: - One of the followers is promoted to leader - Clients need to be reconfigured to send their writes to the new leader - Other followers need to consume data changes from the new leader</p> <p>Failover can be  - Initiated by admin - Automated</p> <p>In Automated failover, - Nodes usually send messages back and forth between each other. If any node does not respond for some timeout, it is considered as dead (after 30 secs). If the leader is dead, it triggers the automated failover process. - New leader is chosen by remaining replicas:     a. The node with latest update from old leader is made new leader (minimizes data loss)     b. next leader is chosen by a controller node (Controller node was chosen earlier, maybe when system started)</p> <pre><code>Note: Getting all remaining nodes to agree on a new leader is a consensus problem.\n</code></pre> <p>Failover is fraught with issues: - In asynchronous replication, the new leader may not have received all writes from the old leader. What if, after the new leader is elected, the old leader comes back? Now what if the new leader has already accepted conflicting writes? You may decide to ignore/drop the writes into the old leader, but that may violate clients' durability expectations. - Discarding writes may need to be addressed in other systems as well. In an incident at GitHub, an out-of-date MySQL follower was promoted to leader. The database system used auto-incrementing primary keys. The new leader reused primary keys previously assigned by the old leader. The primary keys were referenced in a Redis store. The reuse of primary keys caused a discrepancy between MySQL and Redis, which caused some private data to be disclosed to incorrect users. - In certain fault scenarios, it can happen that two nodes believe they are both the leader. The situation is called split brain, and both leaders may accept writes. If there is no conflict resolution approach, data can get lost or corrupted. As a safety catch in split brain situations, one leader is forced to shut down. We must be careful not to shut down both leaders (which may happen in further error scenarios). - Discussion exists about what should be the ideal timeout before failover is triggered. Too soon - then if the timeout happened due to an overloaded leader, unnecessary failure can just worsen the situation. Too long - longer time to recovery.</p> <p>In general, issues related to node failures, unreliable networks, trade-offs around replica consistency, durability, availability, and latency are fundamental problems in distributed systems.</p>"},{"location":"Distributed%20Systems/Replication/#implementation-of-replication-logs","title":"Implementation of replication logs","text":"<ol> <li>Statement based replication (not used now) Leader logs statements that it executes (In relational db - Insert, update or delete) and forwards them to its followers. Each follower processes the statements as if it was received from client.</li> </ol> <p>Disadvantages: - Statements may use non deterministic functions e.g NOW() or RAND() that may generate different value on each replica. - Statements need to be executed in exactly the same order on each replica. This can be challenging when there are multiple concurrently executing transactions. - Statements that have side effects (e.g., triggers, stored procedures, user-defined functions) may generate different results unless the side effects are exactly deterministic.</p> <p>Solution - Leader may replace non deterministic function calls like NOW() with its value before its logged so replicas use value directly. But there can be a lot of edge cases therefore this method is not desired. Statement based replication was used in mSQL before version 5.1. Now they use row based replication (discussed later)</p> <ol> <li>Write-Ahead log (WAL) shipping</li> </ol> <p>Every modification is written to an append-only log file. The log is then shipped to followers. Followers process the log to rebuild the state on the leader.</p> <p>Disadv - The log describes data at a very low level, including which bytes were changed on which disk blocks. That is, the log closely relates to the storage format the database uses. If the database changes its storage format from one version to another, then it is not possible to run different database versions on the leader and followers. Therefore, such database upgrades can require downtime when the database is not operational.</p> <p>If followers and leader could run different versions, usually followers are upgraded one at a time, then Failover is used to make one of the upgraded replicas as the leader. This is no downtime version upgrade.</p> <p>WAL replication is used by Postgres, Oracle etc.</p> <ol> <li>Logical(row-based) replication.</li> </ol> <p>The system keeps logical track of records that were inserted, delteed or updated. The logs are very high level logical records and not tied to the storage engine format.</p> <p>The log is kept as follows: - For inserted rows, the log contains new values of the columns. - For deleted rows, the log contains enough info to uniquely identify the row that was deleted. Usually, it's the primary key logged. If there is no primary key, then old column values are logged. - For updated rows, the log contains enough info to identify the row that changed and the new changed values. - A transaction that modifies several rows generates several log records followed by a record indicating the transaction was commited.</p> <p>Adv : - The log is decoupled from storage engine internals and format; therefore, the leader and followers can run different versions. - The logs can even be processed by external systems to build custom indexes, caches or data warehouse. This technique is called change data capture.</p> <ol> <li>Trigger based replication</li> </ol> <p>Used when more flexibility is needed compared to other approaches: 1. You want to replicate only subset of the data 2. You want to replicate from one database to another 3. You need conflict resolution logic For these usecases you want to move replication upto the application layer.</p> <p>Many relation db's have Triggers and stored procedures. These are leveraged.</p> <ul> <li> <p>A trigger lets you register custom application code thats executed when data change happens (write operation). The trigger can can write some data into separate table when such changes happen. This new table can be read by an external process which can replicate data change to another system. Databus for Oracle and Bucardo for Postgres work like this.</p> </li> <li> <p>Oracle GoldenGate reads database logs directly and makes data changes available for an application to consume.</p> </li> </ul> <p>Trigger based replication is more manual (prone to bugs, has higher setup overhead) compared to database inbuilt replication. But still useful for some cases.</p>"},{"location":"Distributed%20Systems/Replication/#problems-with-replication-lag","title":"Problems with Replication Lag","text":"<p>In leader based replication, writes go to leader and reads to followers.</p> <p>Ideally when: 1. Data pattern has small number of writes and large number of reads. 2. Reads scalled easily by adding more read replicas</p> <p>However, for it to work well most replicas must be async (If all nodes were sync, single node failure may make whole system un-usable. Also adds write latency)</p> <p>The problem here is that async replicas are eventually consistent. At any moment of time read query on replica and leader may give different results as replca may be lagging behind.  The term \"replication lag\" indicates how far the replica is behind leader.</p>"},{"location":"Distributed%20Systems/Replication/#reading-your-own-writes","title":"Reading Your Own Writes","text":"<p>\"Read after write consistency\" means:</p> <ul> <li>Users always see the data they submitted themselves.</li> <li>It does not guarantee what other users see regarding updates made by the user at any given moment.</li> </ul> <p>This consistency guarantee is a important property of a system. Without it, consider a scenario where a user submits data to the leader and then reloads the page (which may be served by a lagging replica). If the user cannot see the data they just updated, it may create the illusion that the submitted data was lost, leading to confusion and a poor user experience.</p> <p>In leader based replication, reading your own writes can be achieved in several ways: 1. Depending on usecase, you can always read from leader data that the user may have modified themselves. e.g user profile info. Other users profiles can be read from replicas. 2. If most things the user can modify than (1) maybe not be very useful as you will be reading most things from leader, negating the effect of read scaling via replicas.    You could track last user update. Then for a minute direct all read requests to leader. AFter a minute to followers. Obv, assumption is replicas catchup is less than a minute. You could also monitor replication lag and divert read traffic to replicas that have replication lag less than a minute. 3. Client can note down its last update. The include this info in its read requests. System can ensure it serves the reads from replicas that have uptodate info at least up untill that point in time. The last update info may not be timestamp. It could be logical one like the db replication log sequence number for the update. Not chosing time based value avoids problems with clock drift betwen frontend and backend. 4.  </p> <p>Note: If system is distributed across geopgraphical reagions then read querys that need to go to leader must be routed correctly to leader datacenter.</p> <p>Note: Approach that envolves client noting and sharing last update may not work if user can use many devices. Laptop client may not know last update sequence number of the mobile client and so on.</p>"},{"location":"Distributed%20Systems/Replication/#monotonic-reads","title":"Monotonic reads","text":"<p>Since several replicas can be lagging by different amounts. There can be case that if clients does multiple read requests (to different replicas) he can see things moving backwards in time.</p> <p>E.g Imagine if app is incrementing counter and saving to db.  Read requests on replicas could return Query 1- Replica one says count = 100 (replica lag 1s) Query 2- Replica two says count = 50  (replica lag 100 s)</p> <p>\"Monotonic read\" guarentee means that a client may see outdated data, but subsequent read requests should never see older data than waht was previously read. i.e cannot see data backwards in time.</p> <p>Can be achieved by user always making qeuery to same read replica. Different user may query different replica. Users replica may be choses using hash of user ID rather than randomly. If replica fails another replica must be chosen (chosen replica must have = or lesser lag)</p>"},{"location":"Distributed%20Systems/Replication/#consistent-prefix-reads","title":"Consistent prefix reads","text":"<p>Imagine if there are 2 db shards. Shard 1 has leader and followers. Shard 2 has leader and followers. Even if \"Monotonic read\" consistency is guarenteed inside a Shard. Issues can occure while query across Shards.</p> <p>E.g  Client A writes to leader of shard 1 : \"How far in future can you see Mr Cake\". Client B responds to leader of shard 2\" : \"10 mins in future\"</p> <p>3rd party client C needs to query both shards 1 and 2 to see whole conversation. He queries replicas. He may B's response before A's question.</p> <p>This issue happpens because to make sense client A and client B interactions are causaly related.</p> <p>\"Consistent prefix\" guarentee means if writes appear in some order, than anyone reading thos writes must also read data in same order.  Issue is quite common in sharded or partitioned databases. Partitions operate independently and there is no global ordering of writes betwen the partitions.</p> <p>Solution - write causially realted data to same partition. There are also algos (discussed later) that keep track of causial dependencies across shards partitions.</p>"},{"location":"Distributed%20Systems/Replication/#solutions-to-replication-lag","title":"Solutions to replication lag","text":"<ol> <li>Depends on use case. Large lag may not be issue in some systems.</li> <li>Depending on use cases. Stronger guarentees can be provided by changing app behaviour as discussed in Reading your own writes, monotic read and consistent prefix reads.</li> <li>Some databases aim to provide stornger guarentees via distributed transactions. But many distributed databases decided to abandon them claiming transactions are too expensive in terms of performance and availabiliuty and asserting that eventual consistent systems are inevitable in a scalable system.</li> </ol>"},{"location":"Distributed%20Systems/Replication/#2-multi-leader-replication","title":"2. Multi-Leader Replication","text":"<p>Single leader replication has the drawback that only one node accepts writes. If that node is not reachable no writes are possible.</p> <p>Multi leader replication is logical extension to this idea where more than one node in the cluster accepts writes. Replication occures in same way as it did before. A leader node simultaneously acts as replica for other leader nodes.</p>"},{"location":"Distributed%20Systems/Replication/#multi-datacenter-operation","title":"Multi datacenter operation","text":"<ul> <li>Unique flavour of multi leader replication</li> <li>Each data center has leader and followers.</li> <li>Leader shares updates with its local followers. Leader also replicates updates asyc to leaders in other datacenters. Leaders are responsible for conflict resolution when updates from other leaders conflict with its data representation.</li> </ul> <p>Advantages: - System operates even if one datacenter fails. Both writes and reads are processed. Compared to single leader replication where entrie system is offline if leader datacenter fails and untill failover is completed. - Lower latency on write path as it is processed by leader in gerographicaly closest datacenter. Most latency comes by request travelling over public low trust internet. In single leader, write request travels over public internet for longer duration as it makes it way to the leader node.</p> <p>Some databases support multi leader mode by default. But for most others need external tools e.g BDR for postgres, Tungsten Replicator for MySQL and Goldern gate for Oracle.</p> <p>Disadvantages: - Leaders need conflict resolution process. - Many databases multi leader operation is retrofitted feature and there can be suprising interactions with other database features like autoincrementing keys, triggers and constainsts.</p> <p>NOTE: Usualy multi leader operation is avoided if posssible.</p>"},{"location":"Distributed%20Systems/Replication/#clients-with-offline-operation","title":"Clients with offline operation","text":"<ul> <li>Usecase for multi leader replication is when application needs to continue to work when its disconected from the internet.</li> <li>e.g calendar app on your phone. YOu need to be able to see your meetings (read requests) and enter new meetings (write requests) at any time even without internet connection. The changes are synced when your device comes back online. This usecase is like multi data center operation where each device is like a datacenter and the connection betwen them is extremely unreliable. </li> </ul> <p>CouchDB is document style NO SQL db specialising in this mode of operation</p>"},{"location":"Distributed%20Systems/Replication/#colaborative-editing","title":"Colaborative editing","text":"<p>In colaborative editing (google docs) multiple users can edit same document at same time. Under the hood user changes are commited to their local leader. Then async replicated to central server and onwards to wards other users. Conflict resolution process is important when clashes occure (discussed later).  In such editers the unit of change is usually very small like a single key stroke.</p> <p>If this approach was not employed. user would have to lock whole document for editing and other user would have to wait when it was locked.</p>"},{"location":"Distributed%20Systems/Replication/#handling-write-conflicts","title":"Handling Write conflicts","text":"<p>Since leaders accepts writes to their local instances. Any conflicts are detected only much later when changes are asyc replicated. It may be days after user actually received saved confirm msg.</p> <p>This does not happen in single leader systems. Here, second write either is blocked, wait for first one to complete or fail in error. The user is forced to retry the second write on top of first one.</p>"},{"location":"Distributed%20Systems/Replication/#conflict-avoidance","title":"Conflict avoidance","text":"<p>If there are resources that could be overwritten, we could design system to ensure they are handled by same leader. For example, a user can be assigned to single datacenter (closest to him), reads and write for that user are handled by the same datacenter, so conflict is avoided across leaders. Other users may be assigned different home datacenters. This strategy avoids concurrent writes across different leaders.</p>"},{"location":"Distributed%20Systems/Replication/#converging-towards-a-consistent-state","title":"Converging towards a consistent state","text":"<p>In sigle leader system, if multiple writes are made to a record the last write reflects the record state.</p> <p>In multi leader system, in general there is no such ordering of writes. If replica simple applied writes inorder they were received, different replicas may end up with different final state (depending on replication propagation lag of various write requests). There must be a way that all replicas arrive at same final value once all changes are replicated.</p> <p>Strategies for achieving convergent conflict resolution: 1. Give each write a timestamp. Last timestamp wins other older write changes are discarded. - Strategy is prone to dataloss (due to non synced clocks) 2. Give each write a unique ID. ID is derived from node id. During conflict highest ID wins (write at higher numbered replica always takes precedence over writes that originated at lower numbered replica). Stratgy is also prone to dataloss. 3. Somehow merge the values together. e.g if there is conflict in writing the title of a doc. Simply append all the possible conflicting titles together e.g titleA/titleB 4. Record the conflict in an explicit datastructure that preserves all the information and write application code that resolves the conflict at some later time (perhaps by prompting the user).</p> <p>Conflicts handled via application code can be reolved in 2 ways. 1. on Write - As soon as system detects conflict in the log of replicated changes it calls a conflict resolution handler (Bucardo in postgres allows you to write perl script for this purpose). The handler cannot prompt the user. It runs a background process and must resolve the conflict quickly. 2. On Read - Details about the conflict are stored in a datastructure. The structure is returned when the record is read by an application. Application will prompt the user to manually resolve the conflict and write final result back to DB. Couch DB works this way.</p> <p>Conflict resolution applies at the level of record (row) or document (no Sql db) not transaction level. i.e if transaction causes multiple writes each write is separate conflict that is resolved independently.</p> <p>Some research is ongoing for automatically resolving conflict. - Conflict-free replicated datatypes - Family of datastructures for sets, maps, ordered lists, counters etc that can be concurrently edited by multiple users and automatically resolve conflict in sensable ways. - Mergable persistent data structures - track history explicitly similar to git version control and use some merge functions. - Operational transformation- designed for concurrently editing an orderd list of items such as list of characters that consititute text document (used in google docs)</p>"},{"location":"Distributed%20Systems/Replication/#multileader-replication-topologies","title":"Multileader replication topologies","text":"<p>If more than one leader node exists, then replication betwen leaders can be organised as topologies</p> <p>(a) Circular - Each leader receives writes from one other leader and forwards those writes along with any of its own to the next leader in the circular chain. (b) Star/Tree - There is one root node. The root nodes receives and propagates writes to all other nodes (c) All to All - Every leader forwards writes to every other leader</p> <p>To prevent infinite looping in (a) and (b), each node is given an identifier and replicated writes are tagged with all node ids that it passed theough. A node that sees its own ID then discards the replicated write as it applied it earlier.</p> <p>Disadvantage of (a) and (b) is that if a node goes down in the chain end to end replication stops untill faulty node is repaired. Technically, topologie can also be reconfigured to work around the fault node but it usualy is a manual process.</p> <p>Disadvantage of (c) is that replication paths may have different latency. Writes may appear in random order. E.g An update statement may appear before the insert statement it relied on. The problem is similar to earlier problem of \"Consistent prefix reads\". To oder these writes correctly a technique called version vectors is used.</p>"},{"location":"Distributed%20Systems/Replication/#3-leaderless-replication","title":"3. Leaderless Replication","text":""}]}